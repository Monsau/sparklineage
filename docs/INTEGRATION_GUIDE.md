# ğŸ”§ Integration Guide | Guide d'IntÃ©gration | GuÃ­a de IntegraciÃ³n

*How to integrate automatic lineage tracking into your existing Spark environment*

---

## ğŸŒ Languages
- [ğŸ‡«ğŸ‡· FranÃ§ais](#franÃ§ais)
- [ğŸ‡¬ğŸ‡§ English](#english)  
- [ğŸ‡ªğŸ‡¸ EspaÃ±ol](#espaÃ±ol)
- [ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©](#Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©)

---

## ğŸ‡«ğŸ‡· FranÃ§ais

### ğŸ¯ IntÃ©gration dans un Spark Existant

#### 1. **Ajouter les JARs nÃ©cessaires**

```bash
# TÃ©lÃ©charger les JARs requis
wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.33/mysql-connector-java-8.0.33.jar
wget https://github.com/OpenLineage/OpenLineage/releases/download/1.13.1/openlineage-spark_2.12-1.13.1.jar
wget https://github.com/open-metadata/OpenMetadata/releases/download/1.0.0/openmetadata-spark-agent.jar
```

#### 2. **Configuration Spark pour Lineage Automatique**

**Option A: Via spark-submit**
```bash
spark-submit \
  --master yarn \
  --jars openmetadata-spark-agent.jar,mysql-connector-j-8.0.33.jar \
  --conf "spark.extraListeners=io.openlineage.spark.agent.OpenLineageSparkListener" \
  --conf "spark.openmetadata.transport.type=openMetadata" \
  --conf "spark.openmetadata.transport.hostPort=http://your-openmetadata:8585/api" \
  --conf "spark.openmetadata.transport.jwtToken=YOUR_JWT_TOKEN" \
  --conf "spark.openmetadata.transport.pipelineServiceName=your_pipeline_service" \
  your_spark_job.py
```

**Option B: Via spark-defaults.conf**
```properties
# /path/to/spark/conf/spark-defaults.conf
spark.jars                              /path/to/jars/openmetadata-spark-agent.jar,/path/to/jars/mysql-connector-j-8.0.33.jar
spark.extraListeners                    io.openlineage.spark.agent.OpenLineageSparkListener
spark.openmetadata.transport.type       openMetadata
spark.openmetadata.transport.hostPort   http://your-openmetadata:8585/api
spark.openmetadata.transport.jwtToken   YOUR_JWT_TOKEN
spark.openmetadata.transport.pipelineServiceName your_pipeline_service
```

**Option C: Dans votre code Spark**
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("YourAppWithLineage") \
    .config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener") \
    .config("spark.openmetadata.transport.type", "openMetadata") \
    .config("spark.openmetadata.transport.hostPort", "http://your-openmetadata:8585/api") \
    .config("spark.openmetadata.transport.jwtToken", "YOUR_JWT_TOKEN") \
    .config("spark.openmetadata.transport.pipelineServiceName", "your_pipeline_service") \
    .getOrCreate()
```

#### 3. **Configuration OpenMetadata**

1. **CrÃ©er un Bot Token**
```bash
# Dans OpenMetadata UI
Settings â†’ Bots â†’ Add Bot â†’ Generate JWT Token
```

2. **Configurer les Services de DonnÃ©es**
```bash
# CrÃ©er les services MySQL source et target
Settings â†’ Services â†’ Databases â†’ Add MySQL Service
```

3. **Configurer le Pipeline Service**
```bash
# CrÃ©er le service pipeline
Settings â†’ Services â†’ Pipelines â†’ Add Pipeline Service
```

#### 4. **Variables d'Environnement**

```bash
# Variables optionnelles pour simplifier la configuration
export OPENMETADATA_HOST="http://your-openmetadata:8585/api"
export OPENMETADATA_JWT_TOKEN="your_jwt_token"
export PIPELINE_SERVICE_NAME="your_pipeline_service"
```

#### 5. **Exemple d'IntÃ©gration ComplÃ¨te**

```python
# your_existing_job.py avec lineage automatique
from pyspark.sql import SparkSession
import os

def create_spark_session_with_lineage():
    """CrÃ©er une session Spark avec lineage automatique"""
    
    # Configuration OpenMetadata
    jwt_token = os.getenv('OPENMETADATA_JWT_TOKEN', 'your_default_token')
    openmetadata_host = os.getenv('OPENMETADATA_HOST', 'http://localhost:8585/api')
    pipeline_service = os.getenv('PIPELINE_SERVICE_NAME', 'spark_pipeline_service')
    
    # Chemins des JARs
    jar_path = "/path/to/your/jars"
    mysql_jar = f"{jar_path}/mysql-connector-j-8.0.33.jar"
    openmetadata_jar = f"{jar_path}/openmetadata-spark-agent.jar"
    
    return SparkSession.builder \
        .appName("ExistingJobWithLineage") \
        .config("spark.jars", f"{openmetadata_jar},{mysql_jar}") \
        .config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener") \
        .config("spark.openmetadata.transport.type", "openMetadata") \
        .config("spark.openmetadata.transport.hostPort", openmetadata_host) \
        .config("spark.openmetadata.transport.jwtToken", jwt_token) \
        .config("spark.openmetadata.transport.pipelineServiceName", pipeline_service) \
        .config("spark.openmetadata.transport.pipelineName", "existing_etl_pipeline") \
        .getOrCreate()

# Votre code ETL existant
def your_existing_etl():
    spark = create_spark_session_with_lineage()
    
    # Vos transformations existantes - le lineage sera automatique !
    df_source = spark.read \
        .format("jdbc") \
        .option("url", "jdbc:mysql://source:3306/database") \
        .option("dbtable", "your_table") \
        .option("user", "user") \
        .option("password", "password") \
        .load()
    
    # Transformations
    df_transformed = df_source.select("col1", "col2").filter("col1 > 10")
    
    # Ã‰criture - lineage automatiquement capturÃ©
    df_transformed.write \
        .format("jdbc") \
        .option("url", "jdbc:mysql://target:3306/database") \
        .option("dbtable", "target_table") \
        .option("user", "user") \
        .option("password", "password") \
        .mode("overwrite") \
        .save()
    
    spark.stop()

if __name__ == "__main__":
    your_existing_etl()
```

---

## ğŸ‡¬ğŸ‡§ English

### ğŸ¯ Integration into Existing Spark

#### 1. **Add Required JARs**

```bash
# Download required JARs
wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.33/mysql-connector-java-8.0.33.jar
wget https://github.com/OpenLineage/OpenLineage/releases/download/1.13.1/openlineage-spark_2.12-1.13.1.jar
wget https://github.com/open-metadata/OpenMetadata/releases/download/1.0.0/openmetadata-spark-agent.jar
```

#### 2. **Spark Configuration for Automatic Lineage**

**Option A: Via spark-submit**
```bash
spark-submit \
  --master yarn \
  --jars openmetadata-spark-agent.jar,mysql-connector-j-8.0.33.jar \
  --conf "spark.extraListeners=io.openlineage.spark.agent.OpenLineageSparkListener" \
  --conf "spark.openmetadata.transport.type=openMetadata" \
  --conf "spark.openmetadata.transport.hostPort=http://your-openmetadata:8585/api" \
  --conf "spark.openmetadata.transport.jwtToken=YOUR_JWT_TOKEN" \
  --conf "spark.openmetadata.transport.pipelineServiceName=your_pipeline_service" \
  your_spark_job.py
```

**Option B: Via spark-defaults.conf**
```properties
# /path/to/spark/conf/spark-defaults.conf
spark.jars                              /path/to/jars/openmetadata-spark-agent.jar,/path/to/jars/mysql-connector-j-8.0.33.jar
spark.extraListeners                    io.openlineage.spark.agent.OpenLineageSparkListener
spark.openmetadata.transport.type       openMetadata
spark.openmetadata.transport.hostPort   http://your-openmetadata:8585/api
spark.openmetadata.transport.jwtToken   YOUR_JWT_TOKEN
spark.openmetadata.transport.pipelineServiceName your_pipeline_service
```

**Option C: In your Spark code**
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("YourAppWithLineage") \
    .config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener") \
    .config("spark.openmetadata.transport.type", "openMetadata") \
    .config("spark.openmetadata.transport.hostPort", "http://your-openmetadata:8585/api") \
    .config("spark.openmetadata.transport.jwtToken", "YOUR_JWT_TOKEN") \
    .config("spark.openmetadata.transport.pipelineServiceName", "your_pipeline_service") \
    .getOrCreate()
```

---

## ğŸ‡ªğŸ‡¸ EspaÃ±ol

### ğŸ¯ IntegraciÃ³n en Spark Existente

#### 1. **Agregar JARs Requeridos**

```bash
# Descargar JARs requeridos
wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.33/mysql-connector-java-8.0.33.jar
wget https://github.com/OpenLineage/OpenLineage/releases/download/1.13.1/openlineage-spark_2.12-1.13.1.jar
wget https://github.com/open-metadata/OpenMetadata/releases/download/1.0.0/openmetadata-spark-agent.jar
```

#### 2. **ConfiguraciÃ³n Spark para Linaje AutomÃ¡tico**

**OpciÃ³n A: Via spark-submit**
```bash
spark-submit \
  --master yarn \
  --jars openmetadata-spark-agent.jar,mysql-connector-j-8.0.33.jar \
  --conf "spark.extraListeners=io.openlineage.spark.agent.OpenLineageSparkListener" \
  --conf "spark.openmetadata.transport.type=openMetadata" \
  --conf "spark.openmetadata.transport.hostPort=http://your-openmetadata:8585/api" \
  --conf "spark.openmetadata.transport.jwtToken=YOUR_JWT_TOKEN" \
  --conf "spark.openmetadata.transport.pipelineServiceName=your_pipeline_service" \
  your_spark_job.py
```

---

## ğŸ‡¸ğŸ‡¦ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

### ğŸ¯ Ø§Ù„ØªÙƒØ§Ù…Ù„ Ù…Ø¹ Spark Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯

#### 1. **Ø¥Ø¶Ø§ÙØ© Ù…Ù„ÙØ§Øª JAR Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©**

```bash
# ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª JAR Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
wget https://repo1.maven.org/maven2/mysql/mysql-connector-java/8.0.33/mysql-connector-java-8.0.33.jar
wget https://github.com/OpenLineage/OpenLineage/releases/download/1.13.1/openlineage-spark_2.12-1.13.1.jar
wget https://github.com/open-metadata/OpenMetadata/releases/download/1.0.0/openmetadata-spark-agent.jar
```

#### 2. **ØªÙƒÙˆÙŠÙ† Spark Ù„ØªØªØ¨Ø¹ Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ**

**Ø§Ù„Ø®ÙŠØ§Ø± Ø£: Ø¹Ø¨Ø± spark-submit**
```bash
spark-submit \
  --master yarn \
  --jars openmetadata-spark-agent.jar,mysql-connector-j-8.0.33.jar \
  --conf "spark.extraListeners=io.openlineage.spark.agent.OpenLineageSparkListener" \
  --conf "spark.openmetadata.transport.type=openMetadata" \
  --conf "spark.openmetadata.transport.hostPort=http://your-openmetadata:8585/api" \
  --conf "spark.openmetadata.transport.jwtToken=YOUR_JWT_TOKEN" \
  --conf "spark.openmetadata.transport.pipelineServiceName=your_pipeline_service" \
  your_spark_job.py
```

**Ø§Ù„Ø®ÙŠØ§Ø± Ø¨: Ø¹Ø¨Ø± spark-defaults.conf**
```properties
# /path/to/spark/conf/spark-defaults.conf
spark.jars                              /path/to/jars/openmetadata-spark-agent.jar,/path/to/jars/mysql-connector-j-8.0.33.jar
spark.extraListeners                    io.openlineage.spark.agent.OpenLineageSparkListener
spark.openmetadata.transport.type       openMetadata
spark.openmetadata.transport.hostPort   http://your-openmetadata:8585/api
spark.openmetadata.transport.jwtToken   YOUR_JWT_TOKEN
spark.openmetadata.transport.pipelineServiceName your_pipeline_service
```

**Ø§Ù„Ø®ÙŠØ§Ø± Ø¬: ÙÙŠ ÙƒÙˆØ¯ Spark Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ**
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("YourAppWithLineage") \
    .config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener") \
    .config("spark.openmetadata.transport.type", "openMetadata") \
    .config("spark.openmetadata.transport.hostPort", "http://your-openmetadata:8585/api") \
    .config("spark.openmetadata.transport.jwtToken", "YOUR_JWT_TOKEN") \
    .config("spark.openmetadata.transport.pipelineServiceName", "your_pipeline_service") \
    .getOrCreate()
```

#### 3. **ØªÙƒÙˆÙŠÙ† OpenMetadata**

1. **Ø¥Ù†Ø´Ø§Ø¡ Ø±Ù…Ø² Bot Token**
```bash
# ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© OpenMetadata
Settings â†’ Bots â†’ Add Bot â†’ Generate JWT Token
```

2. **ØªÙƒÙˆÙŠÙ† Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª**
```bash
# Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø§Øª MySQL Ù„Ù„Ù…ØµØ¯Ø± ÙˆØ§Ù„Ù‡Ø¯Ù
Settings â†’ Services â†’ Databases â†’ Add MySQL Service
```

3. **ØªÙƒÙˆÙŠÙ† Ø®Ø¯Ù…Ø© Pipeline**
```bash
# Ø¥Ù†Ø´Ø§Ø¡ Ø®Ø¯Ù…Ø© pipeline
Settings â†’ Services â†’ Pipelines â†’ Add Pipeline Service
```

#### 4. **Ù…ØªØºÙŠØ±Ø§Øª Ø§Ù„Ø¨ÙŠØ¦Ø©**

```bash
# Ù…ØªØºÙŠØ±Ø§Øª Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© Ù„ØªØ¨Ø³ÙŠØ· Ø§Ù„ØªÙƒÙˆÙŠÙ†
export OPENMETADATA_HOST="http://your-openmetadata:8585/api"
export OPENMETADATA_JWT_TOKEN="your_jwt_token"
export PIPELINE_SERVICE_NAME="your_pipeline_service"
```

#### 5. **Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„ÙƒØ§Ù…Ù„**

```python
# your_existing_job.py Ù…Ø¹ ØªØªØ¨Ø¹ Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
from pyspark.sql import SparkSession
import os

def create_spark_session_with_lineage():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Spark Ù…Ø¹ ØªØªØ¨Ø¹ Ø§Ù„Ù†Ø³Ø¨ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ"""
    
    # ØªÙƒÙˆÙŠÙ† OpenMetadata
    jwt_token = os.getenv('OPENMETADATA_JWT_TOKEN', 'your_default_token')
    openmetadata_host = os.getenv('OPENMETADATA_HOST', 'http://localhost:8585/api')
    pipeline_service = os.getenv('PIPELINE_SERVICE_NAME', 'spark_pipeline_service')
    
    # Ù…Ø³Ø§Ø±Ø§Øª Ù…Ù„ÙØ§Øª JAR
    jar_path = "/path/to/your/jars"
    mysql_jar = f"{jar_path}/mysql-connector-j-8.0.33.jar"
    openmetadata_jar = f"{jar_path}/openmetadata-spark-agent.jar"
    
    return SparkSession.builder \
        .appName("ExistingJobWithLineage") \
        .config("spark.jars", f"{openmetadata_jar},{mysql_jar}") \
        .config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener") \
        .config("spark.openmetadata.transport.type", "openMetadata") \
        .config("spark.openmetadata.transport.hostPort", openmetadata_host) \
        .config("spark.openmetadata.transport.jwtToken", jwt_token) \
        .config("spark.openmetadata.transport.pipelineServiceName", pipeline_service) \
        .config("spark.openmetadata.transport.pipelineName", "existing_etl_pipeline") \
        .getOrCreate()

# ÙƒÙˆØ¯ ETL Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ Ù„Ø¯ÙŠÙƒ
def your_existing_etl():
    spark = create_spark_session_with_lineage()
    
    # Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø© Ù„Ø¯ÙŠÙƒ - Ø³ÙŠØªÙ… ØªØªØ¨Ø¹ Ø§Ù„Ù†Ø³Ø¨ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹!
    df_source = spark.read \
        .format("jdbc") \
        .option("url", "jdbc:mysql://source:3306/database") \
        .option("dbtable", "your_table") \
        .option("user", "user") \
        .option("password", "password") \
        .load()
    
    # Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª
    df_transformed = df_source.select("col1", "col2").filter("col1 > 10")
    
    # Ø§Ù„ÙƒØªØ§Ø¨Ø© - ÙŠØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù†Ø³Ø¨ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    df_transformed.write \
        .format("jdbc") \
        .option("url", "jdbc:mysql://target:3306/database") \
        .option("dbtable", "target_table") \
        .option("user", "user") \
        .option("password", "password") \
        .mode("overwrite") \
        .save()
    
    spark.stop()

if __name__ == "__main__":
    your_existing_etl()
```

---

## ğŸ” Troubleshooting | DÃ©pannage | SoluciÃ³n de Problemas | Ø§Ø³ØªÙƒØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡

### Erreurs Communes / Common Errors / Errores Comunes / Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©

**1. JWT Token Invalide / Ø±Ù…Ø² JWT ØºÙŠØ± ØµØ§Ù„Ø­**
```
Error: 401 Unauthorized - Token verification failed
Solution: RÃ©gÃ©nÃ©rer le token dans OpenMetadata UI / Ø¥Ø¹Ø§Ø¯Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ù…Ø² ÙÙŠ ÙˆØ§Ø¬Ù‡Ø© OpenMetadata
```

**2. JAR non trouvÃ© / Ù…Ù„Ù JAR ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯**
```
Error: ClassNotFoundException: io.openlineage.spark.agent.OpenLineageSparkListener
Solution: VÃ©rifier le chemin des JARs et les permissions / Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø³Ø§Ø± Ù…Ù„ÙØ§Øª JAR ÙˆØ§Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª
```

**3. Connexion OpenMetadata / Ø§ØªØµØ§Ù„ OpenMetadata**
```
Error: Connection refused to OpenMetadata
Solution: VÃ©rifier que OpenMetadata est dÃ©marrÃ© et accessible / Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ´ØºÙŠÙ„ OpenMetadata ÙˆØ¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ÙˆØµÙˆÙ„ Ø¥Ù„ÙŠÙ‡
```

## ğŸ“š Resources | Ressources | Recursos

- [OpenMetadata Documentation](https://docs.open-metadata.org/)
- [OpenLineage Spark Integration](https://openlineage.io/docs/integrations/spark/)
- [Apache Spark Configuration](https://spark.apache.org/docs/latest/configuration.html)