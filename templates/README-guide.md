# =====================================================================
# GUIDE COMPLET : CODE ESSENTIEL LINEAGE SPARK OPENMETADATA
# =====================================================================

## ğŸ¯ OBJECTIF
Ce guide identifie exactement le code minimal nÃ©cessaire pour implÃ©menter 
le lineage Spark avec OpenMetadata, basÃ© sur notre implÃ©mentation rÃ©ussie.

## ğŸ“ STRUCTURE DES FICHIERS FOURNIS

```
templates/
â”œâ”€â”€ docker-compose-lineage.yml     # Infrastructure Docker minimale
â”œâ”€â”€ spark_lineage_template.py      # Code Spark avec lineage  
â”œâ”€â”€ setup_lineage_environment.py   # Script de setup automatique
â””â”€â”€ README-guide.md                # Ce guide
```

## ğŸ”§ COMPOSANTS CRITIQUES IDENTIFIÃ‰S

### 1. INFRASTRUCTURE DOCKER OBLIGATOIRE

**Services essentiels dans docker-compose.yml :**
- âœ… `openmetadata-server:1.9.7` - Service principal
- âœ… `postgresql` - Base mÃ©tadata OpenMetadata  
- âœ… `elasticsearch:8.10.2` - Indexation/recherche (OBLIGATOIRE)
- âœ… `mysql-source` et `mysql-target` - Bases de donnÃ©es
- âœ… `spark-master:3.5.0` - Cluster Spark

### 2. JARS CRITIQUES REQUIS

**Fichiers JAR obligatoires :**
```bash
# Ã€ tÃ©lÃ©charger et placer dans ./jars/
openmetadata-spark-agent-1.0.jar    # Agent principal lineage
mysql-connector-j-8.0.33.jar        # Driver JDBC MySQL
```

**Source officielle JAR :**
```
https://github.com/open-metadata/openmetadata-spark-agent/releases/download/1.0/openmetadata-spark-agent-1.0.jar
```

### 3. CONFIGURATION SPARK MINIMALE

**Code Spark essentiel :**
```python
from pyspark.sql import SparkSession

spark = (
    SparkSession.builder
    .master("local")
    .appName("SparkLineageDemo")
    
    # âœ… CRITIQUE: JARs obligatoires
    .config("spark.jars", "/path/openmetadata-spark-agent.jar,/path/mysql-connector.jar")
    
    # âœ… CRITIQUE: Listener OpenLineage
    .config("spark.extraListeners", "io.openlineage.spark.agent.OpenLineageSparkListener")
    
    # âœ… CRITIQUE: Transport OpenMetadata
    .config("spark.openmetadata.transport.type", "openmetadata")
    .config("spark.openmetadata.transport.hostPort", "http://localhost:8585/api")
    .config("spark.openmetadata.transport.jwtToken", "YOUR_JWT_TOKEN")
    
    # âœ… CRITIQUE: Configuration pipeline
    .config("spark.openmetadata.transport.pipelineServiceName", "your_service")
    .config("spark.openmetadata.transport.pipelineName", "your_pipeline")
    
    .getOrCreate()
)
```

### 4. CODE ETL GÃ‰NÃ‰RATEUR DE LINEAGE

**OpÃ©rations qui gÃ©nÃ¨rent automatiquement le lineage :**
```python
# LECTURE (gÃ©nÃ¨re INPUT lineage)
source_df = spark.read.format("jdbc").option("url", "jdbc:mysql://...").load()

# TRANSFORMATIONS (gÃ©nÃ¨re PROCESSING lineage)  
transformed_df = source_df.select("*").filter(...)

# Ã‰CRITURE (gÃ©nÃ¨re OUTPUT lineage)
transformed_df.write.format("jdbc").option("url", "jdbc:mysql://...").save()
```

## ğŸš€ UTILISATION DES TEMPLATES

### Ã‰TAPE 1: Setup de l'infrastructure
```bash
# 1. Copier docker-compose-lineage.yml vers votre projet
cp templates/docker-compose-lineage.yml ./docker-compose.yml

# 2. DÃ©marrer l'infrastructure
docker-compose up -d

# 3. Attendre que OpenMetadata soit accessible
# VÃ©rifier: http://localhost:8585
```

### Ã‰TAPE 2: Setup automatique des services
```bash
# 1. Modifier le JWT_TOKEN dans setup_lineage_environment.py
# 2. ExÃ©cuter le setup automatique
python templates/setup_lineage_environment.py
```

### Ã‰TAPE 3: ExÃ©cution du lineage Spark
```bash
# 1. Modifier YOUR_ACTUAL_JWT_TOKEN dans spark_lineage_template.py
# 2. Adapter les configurations host/port si nÃ©cessaire
# 3. ExÃ©cuter le script Spark
python templates/spark_lineage_template.py
```

## ğŸ” POINTS CRITIQUES POUR LE SUCCÃˆS

### âœ… Configuration obligatoire
1. **JAR Agent** : `openmetadata-spark-agent-1.0.jar` version exacte
2. **Listener** : `io.openlineage.spark.agent.OpenLineageSparkListener`
3. **Transport** : `type=openmetadata` + `hostPort` + `jwtToken`
4. **Services** : Database services crÃ©Ã©s dans OpenMetadata
5. **Tables** : DÃ©couvertes via ingestion metadata

### âš ï¸ PiÃ¨ges courants Ã©vitÃ©s
1. **Version JAR** : Utiliser exactement la version 1.0 de l'agent
2. **Network** : Host `host.docker.internal` dans Docker
3. **Driver JDBC** : SpÃ©cifier `com.mysql.cj.jdbc.Driver`
4. **FQN Tables** : Format `service.database.schema.table`
5. **JWT Token** : Token valide avec permissions appropriÃ©es

### ğŸ”§ Configuration rÃ©seau Docker
```yaml
# Dans docker-compose.yml
networks:
  app_net:
    driver: bridge

# Tous les services doivent Ãªtre sur le mÃªme rÃ©seau
services:
  service_name:
    networks:
      - app_net
```

## ğŸ“Š VÃ‰RIFICATION DU SUCCÃˆS

### Logs Spark Ã  rechercher :
```
âœ… "Registered listener io.openlineage.spark.agent.OpenLineageSparkListener"
âœ… "Emitting lineage completed successfully with run id"
âœ… "OpenMetadataTransport: ES fieldQuery REQUEST"
```

### Interface OpenMetadata :
1. **Services** â†’ Pipeline Services â†’ Votre service pipeline
2. **Pipelines** â†’ Votre pipeline â†’ Onglet Lineage
3. **Tables** â†’ mysql-source-service â†’ customers â†’ Onglet Lineage
4. **Tables** â†’ mysql-target-service â†’ customers_copy â†’ Onglet Lineage

## ğŸ¯ RÃ‰SUMÃ‰ EXÃ‰CUTIF

**Le lineage Spark OpenMetadata nÃ©cessite exactement :**

1. **Infrastructure** : OpenMetadata + ElasticSearch + MySQL + Spark
2. **Agent** : `openmetadata-spark-agent-1.0.jar`
3. **Configuration** : Listener + Transport + JWT Token
4. **Services** : Database services crÃ©Ã©s dans OpenMetadata
5. **ETL** : OpÃ©rations Spark JDBC (read/write)

**Le lineage est gÃ©nÃ©rÃ© automatiquement** quand ces composants sont correctement configurÃ©s.

**En cas d'Ã©chec**, le lineage peut Ãªtre crÃ©Ã© manuellement via l'API OpenMetadata comme solution de fallback.

## ğŸ“ SUPPORT

Ce guide est basÃ© sur une implÃ©mentation rÃ©ussie et testÃ©e.
Tous les templates fournis contiennent le code exact qui fonctionne.

Pour toute question, rÃ©fÃ©rez-vous aux scripts de diagnostic inclus
qui permettent de vÃ©rifier chaque composant individuellement.